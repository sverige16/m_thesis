{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # Functipn to split data into training, validation and test sets\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "import glob   # The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order. No tilde expansion is done, but *, ?, and character ranges expressed with [] will be correctly matched.\n",
    "import os   # miscellneous operating system interfaces. This module provides a portable way of using operating system dependent functionality. If you just want to read or write a file see open(), if you want to manipulate paths, see the os.path module, and if you want to read all the lines in all the files on the command line see the fileinput module.\n",
    "import random       \n",
    "from tqdm import tqdm \n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchinfo\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve,log_loss, accuracy_score, f1_score\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score\n",
    "import os\n",
    "import time\n",
    "from time import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "# CMAP (extracting relevant transcriptomic profiles)\n",
    "from cmapPy.pandasGEXpress.parse import parse\n",
    "import cmapPy.pandasGEXpress.subset_gctoo as sg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "from sklearn.decomposition import PCA,FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler,QuantileTransformer\n",
    "from sklearn.metrics import precision_recall_curve,log_loss\n",
    "from sklearn.metrics import average_precision_score,roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 08:57:06.216875\n"
     ]
    }
   ],
   "source": [
    "now = str(datetime.now())\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- hyperparameters ---------------------------------------#\n",
    "# Hyperparameters\n",
    "#testing = False # decides if we take a subset of the data\n",
    "max_epochs = 75 # number of epochs we are going to run \n",
    "# apply_class_weights = True # weight the classes based on number of compounds\n",
    "using_cuda = True # to use available GPUs\n",
    "world_size = torch.cuda.device_count()\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "start = time.time()\n",
    "#now = datetime.datetime.now()\n",
    "#now = now.strftime(\"%d_%m_%Y-%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Downloading all relevant data frames and csv files\n",
    "2. extract the correct transcriptomic profiles\n",
    "3. prepare train vs test columns using one hot encoding\n",
    "4. evaluate results\n",
    "5. save results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading all relevant data frames and csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clue column metadata with columns representing compounds in common with SPECs 1 & 2\n",
    "clue_sig_in_SPECS = pd.read_csv('/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/init_data_expl/clue_sig_in_SPECS1&2.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clue row metadata with rows representing transcription levels of specific genes\n",
    "clue_gene = pd.read_csv('/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/init_data_expl/clue_geneinfo_beta.txt', delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training set, what transcriptomic profiles/compounds are included in only the training set\n",
    "L1000_training = pd.read_csv('/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/data_split_csvs/L1000_training_set.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training set, what transcriptomic profiles/compounds are included in only the training set\n",
    "L1000_validation = pd.read_csv('/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/data_split_csvs/L1000_valid_set.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound ID</th>\n",
       "      <th>sig_id</th>\n",
       "      <th>moa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBK041182</td>\n",
       "      <td>LPROT005_MCF10A_6H:BRD-K37798499:0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBK041182</td>\n",
       "      <td>LPROT004_YAPC_6H:BRD-K37798499:5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBK041182</td>\n",
       "      <td>LPROT002_A375_6H:BRD-K37798499:5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBK041182</td>\n",
       "      <td>LPROT003_PC3_6H:BRD-K37798499:5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBK041182</td>\n",
       "      <td>LPROT005_MCF10A_6H:BRD-K37798499:1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Compound ID                                sig_id  moa\n",
       "0   CBK041182  LPROT005_MCF10A_6H:BRD-K37798499:0.1    0\n",
       "1   CBK041182      LPROT004_YAPC_6H:BRD-K37798499:5    0\n",
       "2   CBK041182      LPROT002_A375_6H:BRD-K37798499:5    0\n",
       "3   CBK041182       LPROT003_PC3_6H:BRD-K37798499:5    0\n",
       "4   CBK041182    LPROT005_MCF10A_6H:BRD-K37798499:1    0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1000_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(L1000_training['moa'].unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold(x_train, x_val):\n",
    "    \"\"\"\n",
    "    This function perform feature selection on the data, i.e. removes all low-variance features below the\n",
    "    given 'threshold' parameter.\n",
    "    \n",
    "    Args:\n",
    "            x_fold_train: K-fold train data with only phenotypic/morphological features and PCs - pandas \n",
    "            dataframe.\n",
    "            x_fold_val: K-fold validation data with only phenotypic/morphological features and PCs - pandas \n",
    "            dataframe.\n",
    "            df_test_x_copy: test data - pandas dataframe with only phenotypic/morphological features and PCs.\n",
    "    \n",
    "    Returns:\n",
    "            x_fold_train: K-fold train data after feature selection - pandas dataframe.\n",
    "            x_fold_val: K-fold validation data after feature selection - pandas dataframe.\n",
    "            df_test_x_copy: test data - pandas dataframe after feature selection - pandas dataframe.\n",
    "    \n",
    "    \"\"\"\n",
    "    var_thresh = VarianceThreshold(threshold = 2) # sets a variance threshold\n",
    "    var_thresh.fit(x_train) # learn empirical variances from X\n",
    "    x_train = x_train.loc[:,var_thresh.variances_ > 2] # locate all variance thresholds above 0.8, keep those columns\n",
    "    x_val = x_val.loc[:,var_thresh.variances_ > 2]\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the gctoo dataframe to extract from\n",
    "# choosing only landmark genes\n",
    "def tprofiles_gc_too_func(L1000_data, clue_gene):\n",
    "    '''\n",
    "    \n",
    "    Input:\n",
    "    L1000: column meta data from clue.io that only includes training/test data\n",
    "    clue_gene: row meta data from clue.io transcriptomic profiles\n",
    "    \n",
    "    Output:\n",
    "    parsed gctoo file with all of the transcriptomic profiles'''\n",
    "\n",
    "    clue_gene[\"gene_id\"] = clue_gene[\"gene_id\"].astype(str)\n",
    "    landmark_gene_row_ids = clue_gene[\"gene_id\"][clue_gene[\"feature_space\"] == \"landmark\"]\n",
    "\n",
    "    # get all samples (across all cell types, doses, and other treatment conditions) with certain MoA\n",
    "    profile_ids = L1000_data[\"sig_id\"]\n",
    "    tprofiles_gctoo = parse(\"/scratch2-shared/erikep/level5_beta_trt_cp_n720216x12328.gctx\", \n",
    "                                    cid= profile_ids, \n",
    "                                    rid = landmark_gene_row_ids)\n",
    "\n",
    "    ### 2. copy the metadata from those samples\n",
    "    # first, we need to subset all the metadata information from our larger metadata DataFrame\n",
    "    # col\n",
    "  \n",
    "    '''\n",
    "    tprofiles_sig_id_info = L1000_training\n",
    "\n",
    "    # row \n",
    "    tprofiles_gene_id_info = clue_gene[clue_gene[\"feature_space\"] == \"landmark\"]\n",
    "\n",
    "    tprofiles_sig_id_info.set_index(\"sig_id\", inplace=True)\n",
    "    # now the data frame is indexed by sig_ids consistent with those of the data_df:\n",
    "    tprofiles_sig_id_info.index\n",
    "\n",
    "    tprofiles_gene_id_info.set_index(\"gene_id\", inplace=True)\n",
    "    # now the data frame is indexed by sig_ids consistent with those of the data_df:\n",
    "    tprofiles_gene_id_info.index\n",
    "\n",
    "    # set the relevant annotations as a col_metadata_df: \n",
    "    tprofiles_gctoo.col_metadata_df = tprofiles_sig_id_info\n",
    "\n",
    "    # set the relevant annotations as a row_metadata_df: \n",
    "    tprofiles_gctoo.row_metadata_df = tprofiles_gene_id_info\n",
    "    '''\n",
    "    return tprofiles_gctoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tprofile(idx):\n",
    "    '''returns transcriptomic profile of of specific ID with in the form of a torch tensor'''\n",
    "    # extract unique column name from L1000 data\n",
    "    # use it to parse the gctoo file\n",
    "    \n",
    "    tprofile_id =  profiles_gc_too.col_metadata_df.iloc[idx]\n",
    "    tprofile_id_sig = [tprofile_id.name] \n",
    "    tprofile_gctoo = sg.subset_gctoo(profiles_gc_too, cid= tprofile_id_sig) \n",
    "    #return torch.tensor(tprofile_gctoo.data_df.values.astype(np.float32)) \n",
    "    return np.asarray(tprofile_gctoo.data_df.values.astype(np.float32))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(df):\n",
    "    '''Splitting data into two parts:\n",
    "    1. input : the pointer showing where the transcriptomic profile is  \n",
    "    2. target one hot : labels (the correct MoA) '''\n",
    "    \n",
    "    # one-hot encoding labels\n",
    "     # creating tensor from all_data.df\n",
    "   #target = torch.tensor(df['moa'].values.astype(np.int64))\n",
    "\n",
    "    # For each row, take the index of the target label\n",
    "    # (which coincides with the score in our case) and use it as the column index to set the value 1.0.‚Äù \n",
    "    #target_onehot = torch.zeros(target.shape[0], num_classes)\n",
    "    #target_onehot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "    target_onehot = df['moa']\n",
    "    input =  df.drop('moa', axis = 1)\n",
    "    \n",
    "    \n",
    "    return input, target_onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_array_transform(profiles_gc_too):\n",
    "    '''\n",
    "    Takes a .gctoo and extracts the correct profile, transforms the profile into a numpy array and then places it into a pandas data_frame.\n",
    "\n",
    "    Input:\n",
    "\n",
    "    Output:\n",
    "    pandas dataframe\n",
    "    '''\n",
    "    rows = []\n",
    "    for i in range(profiles_gc_too.data_df.shape[1]):\n",
    "        rows.append(extract_tprofile(i))\n",
    "    np_array =  np.asarray(rows)\n",
    "    np_array = np_array.squeeze()\n",
    "    df = pd.DataFrame(np_array)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rows = []\\nfor i in range(profiles_gc_too.data_df.shape[1]):\\n    rows.append(extract_tprofile(i))\\nnp_df = pd.DataFrame(rows)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rows = []\n",
    "for i in range(profiles_gc_too.data_df.shape[1]):\n",
    "    rows.append(extract_tprofile(i))\n",
    "np_df = pd.DataFrame(rows)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "beloww takes a long time (8 min)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_gc_too = tprofiles_gc_too_func(L1000_training, clue_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df, labels = splitting(L1000_training) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = np_array_transform(profiles_gc_too)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/scratch2-shared/erikep/data_splits_npy/10_moas_train', df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "14110    8\n",
       "14111    8\n",
       "14112    8\n",
       "14113    8\n",
       "14114    8\n",
       "Name: moa, Length: 14115, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_str = labels.apply(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlb = MultiLabelBinarizer()\\nmlb.fit(labels_str)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labels_str)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels_touse = mlb.fit_transform(labels_str)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''labels_touse = mlb.fit_transform(labels_str)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels_str'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''labels_str'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train_vs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e2ff0eff4f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test with muli-label MlKNN to see if it works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_vs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train_vs' is not defined"
     ]
    }
   ],
   "source": [
    "# Test with muli-label MlKNN to see if it works\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(df_train_vs, labels_train_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a version of grid search to optimize random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "'''taken from https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74'''\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = classifier, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(df_train, labels_train_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/Erik_Models/pickles/Random_Forest_pickles/RF2023-01-18 15:52:55.679817']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(best_random, '/home/jovyan/Tomics-CP-Chem-MoA/04_Tomics_Models/Erik_Models/pickles/Random_Forest_pickles/RF' + now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 80,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(classifier.score(df_train, labels_train_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_numpy = df_train.to_numpy()\n",
    "labels_train = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14115,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14115, 978)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_numpy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_gc_too = tprofiles_gc_too_func(L1000_validation, clue_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = np_array_transform(profiles_gc_too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/scratch2-shared/erikep/data_splits_npy/10_moas_val', df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7\n",
       "1       7\n",
       "2       7\n",
       "3       7\n",
       "4       7\n",
       "       ..\n",
       "1973    2\n",
       "1974    2\n",
       "1975    2\n",
       "1976    2\n",
       "1977    2\n",
       "Name: moa, Length: 1978, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df_val, labels_val = splitting(L1000_validation) \n",
    "labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val_str = labels_val.apply(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train__vs, df_val_vs = variance_threshold(df_train, df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1978, 713)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14115, 713)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train__vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(df_train__vs, labels_train_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(df_val_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2204246713852376"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_val_str, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_predictions = best_random.predict(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22901921132457026"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels_val_str, improved_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07118671577501716"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(labels_val_str, predictions, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   1,   0,   3,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,  13,   0, 111,   0,   0,   0,   0],\n",
       "       [ 52,   0,   0, 120,   5, 128,   0,   0,  30,   0],\n",
       "       [  0,   1,   0, 341,   0, 151,   0,   0,   1,   0],\n",
       "       [  4,   0,   0,  22,   0,  41,   0,   1,  14,   0],\n",
       "       [  0,   0,   0,   9,   0,  95,   0,   0,   0,   0],\n",
       "       [  1,   1,   0,  13,   0,  50,   0,   0,   0,   0],\n",
       "       [ 25,   0,   0,  25,   0,  13,   0,   0,   8,   0],\n",
       "       [ 29,   0,   0, 109,   0, 408,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,  98,   0,  54,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(labels_val_str, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOmething is wrong with the predictions. None of the predictions match, and I am not able to see the matrix produced by predict and predic_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bro = labels_str.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_df_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello_kitty = df_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_trainable = labels_str.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_trainable = labels_trainable.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_neighbors=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index (9917) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-534edd6cedc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello_kitty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_trainable\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skmultilearn/adapt/mlknn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prior_prob_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prior_prob_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# Computing the posterior probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond_prob_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond_prob_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/skmultilearn/adapt/mlknn.py\u001b[0m in \u001b[0;36m_compute_cond\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Dispatch to specialized methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mrow\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m_asindices\u001b[0;34m(self, idx, length)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mmax_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmax_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mmin_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index (9917) out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = MLkNN(k=5)\n",
    "\n",
    "#train\n",
    "classifier.fit(hello_kitty, labels_trainable )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that is actually the training and not the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "14110    8\n",
       "14111    8\n",
       "14112    8\n",
       "14113    8\n",
       "14114    8\n",
       "Name: moa, Length: 14115, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    3535\n",
      "5    3363\n",
      "0    1688\n",
      "8    1592\n",
      "1    1169\n",
      "9     839\n",
      "6     741\n",
      "2     470\n",
      "7     369\n",
      "4     349\n",
      "Name: moa, dtype: int64\n",
      "14115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "apply_class_weights = True\n",
    "if apply_class_weights:     # if we want to apply class weights\n",
    "    counts = labels_train_str.value_counts()  # count the number of moa in each class for the ENTiRE dataset\n",
    "    print(counts)\n",
    "    class_weights = []   # create list that will hold class weights\n",
    "    for moa in labels_train_str.unique():       # for each moa   \n",
    "        #print(moa)\n",
    "        counts[moa]\n",
    "        class_weights.append(counts[moa])  # add counts to class weights\n",
    "    #print(len(class_weights))\n",
    "    #print(class_weights)\n",
    "    #print(type(class_weights))\n",
    "    # class_weights = 1 / (class_weights / sum(class_weights)) # divide all class weights by total moas\n",
    "    print(sum(class_weights))\n",
    "    class_weights = [i / sum(class_weights) for  i in class_weights]\n",
    "    class_weights_dict = {}\n",
    "    for i, num in enumerate(class_weights):\n",
    "        class_weights_dict[str(i)] = num\n",
    "    class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0.1195890896209706,\n",
       " '1': 0.05944031172511512,\n",
       " '2': 0.02614240170031881,\n",
       " '3': 0.024725469358838115,\n",
       " '4': 0.03329791002479632,\n",
       " '5': 0.2504427913567127,\n",
       " '6': 0.23825717321997875,\n",
       " '7': 0.08281969535954659,\n",
       " '8': 0.05249734325185972,\n",
       " '9': 0.11278781438186326}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1195890896209706"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1688/14115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11958909, 0.05944031, 0.0261424 , 0.02472547, 0.03329791,\n",
       "       0.25044279, 0.23825717, 0.0828197 , 0.05249734, 0.11278781])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applying_class_weights_funct(labels_train):\n",
    "    ''' '''\n",
    "    \n",
    "    counts = labels_train.value_counts()  # count the number of moa in each class for the ENTiRE dataset\n",
    "    class_weights = []   # create list that will hold class weights\n",
    "    for moa in labels_train.unique():       # for each moa   \n",
    "        print(moa)\n",
    "        counts[moa]\n",
    "        print(counts[moa])\n",
    "        class_weights.append(counts[moa])  # add counts to class weights\n",
    "    class_weights = [i / sum(class_weights) for  i in class_weights]\n",
    "    class_weights_list = []\n",
    "    for i, num in zip(labels_train.unique(), class_weights):\n",
    "        class_weights_dict = {}\n",
    "        print(num)\n",
    "        cla\n",
    "        class_weights_dict[i] = num\n",
    "        class_weights_list.append(class_weights_dict)\n",
    "    print(class_weights_list)\n",
    "    return class_weights_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " moas = input('List of moas (lst with strs) (ex: [\"cyclooxygenase inhibitor\", \"adrenergic receptor antagonist\"]): ') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"cyclooxygenase inhibitor\", \"adrenergic receptor antagonist\"]'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9 (default, Jan 26 2021, 15:33:00) \n[GCC 8.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
